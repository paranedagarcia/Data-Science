{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5223227a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8453944f",
   "metadata": {},
   "source": [
    "# Data Science\n",
    "### üìö Objetivo General\n",
    "Formar profesionales capaces de adquirir, procesar, analizar y comunicar informaci√≥n basada en datos mediante herramientas de programaci√≥n, estad√≠stica y machine learning, integrando principios √©ticos y buenas pr√°cticas de ciencia de datos.\n",
    "\n",
    "---\n",
    "\n",
    "## üìì M√≥dulo 1: Introducci√≥n al Data Science\n",
    "**Objetivo del m√≥dulo:** Comprender el rol del cient√≠fico de datos y el ciclo de vida de los proyectos de data science.\n",
    "\n",
    "**Resultados de Aprendizaje:**\n",
    "- Entender las etapas de un proyecto de ciencia de datos.\n",
    "- Reconocer el valor de los datos y su impacto en diversas industrias.\n",
    "\n",
    "**Contenidos:**\n",
    "1. Historia y definici√≥n de Data Science\n",
    "2. Conceptos fundamentales y tipos de an√°lisis\n",
    "3. Flujo de trabajo de un proyecto de datos\n",
    "4. Ciclos CRISP-DM y OSEMN\n",
    "5. √âtica y privacidad en datos\n",
    "6. Herramientas y entornos comunes (Python, Jupyter, Git, VS Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72713f",
   "metadata": {},
   "source": [
    "## Introducci√≥n\n",
    "\n",
    "Las organizaciones de todo tipo, hace mucho tiempo que han reconocido la necesidad de almacenar datos y transformarlos en informaci√≥n. Esta informaci√≥n debe ser administrada, planificada, controlada y tratada como un activo. Este activo debe ser manipulado en forma efectiva y eficiente.\n",
    "\n",
    "La tarea de las disciplinas de Inteligencia de Negocios (Business Intelligence), Analisis de Datos (data Analytics) y Ciencia de Datos (Data Science) es tomar unos ciertos datos y transformarlos en informaci√≥n para describir, pronosticar y generar conocimiento a partir de ellos. Para finalmente tomar decisiones basados en esos datos.\n",
    "\n",
    "Sin embargo, para lograr estas metas se deben tener las capacidades de dise√±ar en forma correcta los datos a capturar para esa generaci√≥n de conocimiento. ¬øSe deben colectar todos los datos?, ¬øc√≥mo discriminar aquellos relevantes? ¬øc√≥mo muestrear adecuadamante si no dispongo del universo de datos? ¬øcuando se debe efectuar m√©todos de imputaci√≥n de datos?.\n",
    "\n",
    "![Pir√°mide de la informaci√≥n.](images/datoinfo0.png)\n",
    "\n",
    "## Datos\n",
    "\n",
    "Definamos datos como **Informaci√≥n concreta sobre hechos, elementos, etc., que permite estudiarlos, analizarlos o conocerlos**.\n",
    "\n",
    "\"los datos del censo; el an√°lisis aport√≥ datos de gran inter√©s respecto a la g√©nesis de esta fobia; cada ficha contiene los datos comerciales, fiscales y estad√≠sticos de cada proveedor; estos datos configuran una densidad de poblaci√≥n d√©bil, aunque ello no descarta que haya n√∫cleos muy poblados y muchas regiones vac√≠as\"\n",
    "\n",
    "**Cifra, letra o palabra que se suministra a la computadora como entrada y la m√°quina almacena en un determinado formato**.\n",
    "\n",
    "\"al introducir palabras o n√∫meros en una hoja de c√°lculo, la computadora los procesa y los almacena como datos en c√≥digo binario\"\n",
    "\n",
    "Es una descripci√≥n o imagen relacionados con un hecho, evento, personas, objetos u otras entidades del mundo real. El significado del dato cambia dependiendo dentro del contexto en que se encuentre. El siguiente ejercicio es el que usualmente utilizo en mis clases para la noci√≥n del concepto de datos.\n",
    "\n",
    "-   Considere el n√∫mero **25...**\n",
    "\n",
    "-   Ahora... **25 \"Kilos\"**\n",
    "\n",
    "-   Y ahora... **25 \"kilos\" de \"papas\"**\n",
    "\n",
    "-   Finalmente... **25 \"kilos\" de \"papas\" en \"mercado\" de \"Concepci√≥n\"**\n",
    "\n",
    "### Contexto\n",
    "\n",
    "La b√∫squeda de datos para la generaci√≥n de informaci√≥n se da dentro de cierto √°mbito dentro de toda organizaci√≥n. Las organizaciones de cualquier √≠ndole utilizan e intercambian informaci√≥n, con sus usuarios/clientes y proveedores.\n",
    "\n",
    "![Posici√≥n de base de datos dentro de la organizaci√≥n.](images/informacion.jpg) \n",
    "\n",
    "En este nuevo contexto de alta dependencia de datos (eficientes y de calidad) se crean nuevos perfiles profesionales que suman a los ya tradicionales existentes en d√©cadas pasadas en el √°mbito del uso de las tecnolog√≠as de informaci√≥n.\n",
    "\n",
    "### Or√≠genes de datos\n",
    "\n",
    "La importancia de los datos es clara en su objetivo de otorgar informaci√≥n para la toma de decisiones, las que pueden llevar a una organizaci√≥n al √©xito o fracaso de su gesti√≥n. Ahora bien, si es tan importante los datos tambi√©n lo debeira ser el or√≠gen de donde estos son extra√≠dos, origenes que tambi√©n han evolucionado en el tiempo. Hace no mas de 10 o m√°s a√±os la extracci√≥n de datos proviene de bases de datos expresamente dise√±adas para ello, de planillas de c√°lculo (Excel preferentemente) llenadas a mano por usuarios destinados a ello y por formularios tanto papel como electr√≥nicos, que finalmente terminaban en las bases y planillas antes mencionadas.\n",
    "\n",
    "Actualmente, se suman a las fuentes antes mencionadas un amplio n√∫mero\n",
    "\n",
    "**Bases de datos**\n",
    "\n",
    "Una base de datos es un conjunto organizado de datos que se almacenan y gestionan en un sistema inform√°tico, permitiendo que la informaci√≥n se pueda buscar, consultar y actualizar f√°cilmente cuando se necesite.\n",
    "\n",
    "```{sql}\n",
    "-- Seleccionar toda la informaci√≥n de clientes de Chile.\n",
    "SELECT * FROM clientes WHERE pais = 'Chile'\n",
    "```\n",
    "\n",
    "**Archivos csv**\n",
    "\n",
    "El formato m√°s asequible para acceder a datos es a trav√©s del intercambio de archivos de texto y separados por coma. Este es formato aceptado globalmente y es el tipo de intercambio de datos m√°s utilizado entre dispositivos.\n",
    "\n",
    "\n",
    "### Perfiles y roles profesionales\n",
    "\n",
    "La complejidad de la obtenci√≥n de datos y por tanto la complejidad de la informaci√≥n resultante ha llevado al desarrollo de un mayor n√∫mero de perfiles especialistas, que hasta hace unos 10 a√±os no se ve√≠an en el mercado profesional. El aumento de las fuentes de datos de todo tipo y forma, los nuevas formas de almacenamiento y de procesamiento han establecido una necesidad de mayores especialistas.\n",
    "\n",
    "#### Director de Datos (CDO)\n",
    "\n",
    "El Director de datos (**Chief Data Officer**) [@cdo] es un nuevo rol dentro de aquellas organizaciones[^01-intro-1] con una alta especializaci√≥n y valoraci√≥n de los datos. Es un puente entre el √°rea comercial estrat√©gica y el √°rea TI que combina capacidades tecnol√≥gicas, estad√≠sticas y gerenciales entre otras:\n",
    "\n",
    "[^01-intro-1]: <https://www2.deloitte.com/uy/es/pages/deloitte-analytics/articles/the-chief-data-officer.html>\n",
    "\n",
    "-   Entiende los datos y las necesidades de la empresa respecto a los datos.\n",
    "-   Decide queÃÅ datos deben almacenarse en la base de datos.\n",
    "-   Establece poliÃÅticas para mantener y gestionar los datos almacenados.\n",
    "-   Gestiona los datos como valor estrat√©gico de la organizaci√≥n.\n",
    "-   Establece las bases para el aseguramiento de la calidad de los datos.\n",
    "\n",
    "El conocimiento a cabalidad del √°rea de negocios de la organizaci√≥n es fundamental para este perfil, ya que es qui√©n gu√≠a a traves de todo el proceso de generaci√≥n de informaci√≥n. Define los objetivos para la generaci√≥n de valor del negocio respecto de la informaci√≥n y hace parte la anal√≠tica dentro del objetivo de negocio.\n",
    "\n",
    "> El rol fundamental del CDO se enfoca en sustentar la \"visi√≥n del negocio\" con informaci√≥n.\n",
    "\n",
    "Tambi√©n dentro de su √°rea de acci√≥n se encuentra la gobernanza de los datos y el establecimiento de las pol√≠ticas de uso de la informaci√≥n. Pasan de un rol de administrador a uno m√°s estrat√©gico e innovador que permite responder a los cambios tecnol√≥gicos cambiando sus ambiente de datos en la nuevas √°reas de big data, automatizaci√≥n y aprendizaje de m√°quinas.\n",
    "\n",
    "El CDO dentro de la gobernanza de datos asesora en la implementaci√≥n de pol√≠ticas y coordina tanto lo requisitos como el control de la informaci√≥n sobre los restantes actores.\n",
    "\n",
    "![√Åreas de un CDO.](images/cdo.png){fig-align=\"center\"}\n",
    "\n",
    "La creaci√≥n de un CDO generalmente va acompa√±ada de nuevos perfile asociados dentro de una estrategia de gobierno de datos. Estos nuevos perfiles son por lo general, el due√±o de los datos y el custodio de datos.\n",
    "\n",
    "#### **Due√±o de los Datos (Data owner)**\n",
    "\n",
    "El due√±o de los datos dentro de la organizaci√≥n es un profesional interno de la organizaci√≥n, generalmente conocedor a un alto nivel del negocio de esta, de forma de poder establecer los datos correctos a ser utilizados y las mejoras necesarias para el crecimiento de la organizaci√≥n.\n",
    "\n",
    "Sus funciones no excluyentes son regularmente:\n",
    "\n",
    "-   Precisi√≥n y exactitud de informaci√≥n propia\n",
    "-   Definir reglas de uso y coordinaci√≥n de todos los datos\n",
    "-   Identifica errores\n",
    "-   Define los niveles de calidad y de seguridad de la informaci√≥n\n",
    "-   Responsable de la confidencialidad y privacidad de la informaci√≥n\n",
    "-   Establece el valor de los datos para la organizaci√≥n\n",
    "\n",
    "#### **Custodio de Datos (Data Steward)**\n",
    "\n",
    "Con un aspecto m√°s operativo que estrat√©gico el custodio de los datos es aqu√©l perfil que tiene entre sus responsabilidades la consistencia y accesibilidad a los datos que la organizaci√≥n requiere. Aparece en todas las definiciones aceptadas para este perfil (que pueden encontrarse en Internet), como un intermediario entre el Data Owner y el usuario final de los datos. Y que en organizaciones peque√±as puede estar asociadas al mismo perfil de un Data Owner.\n",
    "\n",
    "En su nivel operativo se encarga de:\n",
    "\n",
    "-   Captura, almacena y retiene informaci√≥n\n",
    "-   Calidad y disponibilidad\n",
    "-   Seguridad\n",
    "\n",
    "#### Data owner vs data steward\n",
    "\n",
    "#### **Arquitecto de Datos (Data Architect - DA)**\n",
    "\n",
    "Es tal la complejidad actual de los datos respecto de sus or√≠genes as√≠ como el volumen de datos que requieren ser transados, que se hace necesaria la participaci√≥n de un nuevo perfil, el arquitecto de datos. Por sobre los perfiles mencionados anteriormente, es el DA el encargado de dise√±ar y orquestar las plataformas necesarias para el procesamiento masivo de datos para su transformaci√≥n en informaci√≥n. Es un perfil netamente operativo encargado de construir y mantener la infraestructura de los datos de la organizaci√≥n.\n",
    "\n",
    "En general el DA es el encargado de dise√±ar y planificar el sistema de infraeastructura de datos y es el ingeniero de datos quien la construye, sin embargo en organizaciones peque√±as estos roles son realizados por el mismo cargo. Por lo que las funciones de un ingeniero de datos, que se detalla m√°s adelante, se pueden consignar a un DA.\n",
    "\n",
    "Sus funciones principales abarcan:\n",
    "\n",
    "-   Dise√±o de modelos de datos seg√∫n las reglas de negocio\n",
    "-   Desarrollo de bases de datos estableciendo el modelo conceptual, l√≥gico y f√≠sico\n",
    "-   Determinar qu√© tecnolog√≠as va a usar y c√≥mo va a hacerlo\n",
    "-   Crear procedimientos para garantizar la exactitud y la accesibilidad de los datos\n",
    "-   Seleccionar los almacenes de datos y las fuentes de los mismos\n",
    "-   Gesti√≥n del flujo de trabajo o workflow. Asegurarse de tener la velocidad de procesamiento y el acceso al almacenamiento para respaldarlo es esencial\n",
    "-   Encargado y principal responsable de que las tres fases de los procesos ETL se cumplan en los tiempos establecidos y se realicen correctamente\n",
    "-   Auditor√≠as de datos: Realizaci√≥n de informes y evaluaci√≥n del trabajo de forma habitual y asegurar la integridad de los datos.\n",
    "\n",
    "#### Ingeniero de Datos (Data Engineer - DE)\n",
    "\n",
    "El trabajo del ingeniero de datos es \"la representaci√≥n y el movimiento de datos para que sean consumibles y utilizables\", dijo Pope. El ingeniero de datos, debe poder tomar los datos sin procesar, limpiarlos, moverlos a una base de datos, etiquetarlos y, en general, asegurarse de que est√©n listos para la siguiente etapa del proceso.\n",
    "\n",
    "Con un amplio manejo de Big Data, este perfil es sumamente t√©cnico. Los ingenieros de datos se encuentran entre los desarrolladores de aplicaciones y los cient√≠ficos de datos. Se encargan de dise√±ar, construir y gestionar los datos y la infraestructura necesaria para almacenarlos y procesarlos. Construyen la base tecnol√≥gica para que los cient√≠ficos de datos y analistas puedan realizar sus tareas. Por lo tanto, son los responsables de mantener sistemas escalables, con alta disponibilidad y rendimiento, integrando nuevas tecnolog√≠as y desarrollando el software necesario.\n",
    "\n",
    "Deben conocer las tecnolog√≠as Big Data Apache Spark, Scala, Docker, Hadoop, HDFS y otras, y entender c√≥mo se integran sus tecnolog√≠as y las formas de procesar, transformar y tratar los datos con herramientas de ingesta y los procesos ETL. Adem√°s, deben saber c√≥mo mover datos hacia y desde los sistemas de Big data y la implementaci√≥n de bases de datos para grandes volumenes de datos. Entre sus funciones tambi√©n se encuentra dar apoyo y facilitar el trabajo a analistas y cient√≠ficos de datos, as√≠ como al negocio.\n",
    "\n",
    "ETL. Procesos de extracci√≥n, transformaci√≥n y carga de datos.\n",
    "\n",
    "Como se trata de procesos complejos y muy integrados se requiere adem√°s un manejo de lenguajes de scripting y conocer procesos de automatizaci√≥n (mediante Python u otro lenguaje) e interacciones con APIs y fuentes de datos externas.\n",
    "\n",
    "Por definici√≥n, el Big Data suele tener lugar en sistemas distribuidos, que es otro de los conocimientos fundamentales para un buen ingeniero de datos. Estos sistemas tienen numerosas particularidades en torno a la replicaci√≥n de datos, consistencia, tolerancia a fallos, particionado y concurrencia. En este punto se englobar√≠an tecnolog√≠as como HDFS, Hadoop o Spark.\n",
    "\n",
    "Habilidades Fundamentales Tecnolog√≠as y servicios Cloud. La demanda de estas tecnolog√≠as no para de crecer, y es que cada vez es m√°s frecuente iniciar proyectos de migraci√≥n a la nube en las empresas. Un buen ingeniero de datos debe conocer y tener experiencia en el uso de servicios cloud, sus ventajas, desventajas y sus aplicaci√≥n en proyectos Big Data. Al menos deber√≠a estar familiarizado con una plataforma como Azure o AWS ya que son las m√°s extendidas. Adem√°s, debe conocer buenas pr√°cticas en cuanto a seguridad de los datos y virtualizaci√≥n. Recuerda que estas tecnolog√≠as han venido para quedarse e invertir tiempo en formarse es siempre una buena idea.\n",
    "\n",
    "Los Ingenieros de Datos tambi√©n deben conocer el funcionamiento y uso de las bases de datos. Tambi√©n las diferencias que existen entre bases de datos relacionales y NoSQL. El lenguaje b√°sico para interactuar con estas bases de datos es SQL, por lo que tambi√©n debe estar familiarizado con escribir consultas de lectura y manipulaci√≥n de datos. Adem√°s, debe entender la diferencia entre los tipos de bases de datos NoSQL y los casos de uso para cada uno de ellos.\n",
    "\n",
    "Uno de los roles principales de los ingenieros de datos es crear pipelines de datos con tecnolog√≠as ETL y frameworks de orquestaci√≥n. En esta secci√≥n podr√≠amos enumerar muchas tecnolog√≠as pero el ingeniero de datos deber√≠a conocer o sentirse c√≥modo con algunas de las m√°s conocidas como puede ser [NiFi](https://nifi.apache.org/) o [Airflow](https://airflow.apache.org/).\n",
    "\n",
    "Las actividades esenciales para este perfil profesional son entre otras y mezcladas habitualmente con las del DA:\n",
    "\n",
    "-   Dise√±o de modelos de datos\n",
    "-   Desarrollo de bases de datos\n",
    "-   Tecnolog√≠as Big Data\n",
    "-   Seleccionar los almacenes de datos y las fuentes de los mismos\n",
    "-   Gesti√≥n del flujo de trabajo (workflow). Asegurarse de tener la velocidad de procesamiento y el acceso al almacenamiento para respaldarlo es esencial\n",
    "-   Responsabilidad sobre las tres fases de los [procesos ETL](https://www.inesdi.com/blog/etl-que-es-procesos-y-herramientas/) se cumplan en los tiempos establecidos y se realicen correctamente\n",
    "-   Auditor√≠as de datos: realizaci√≥n de informes y evaluaci√≥n del trabajo de forma habitual\n",
    "-   Manejo de herramientas de gesti√≥n: Apache Spark, Hadoop, Airflow, etc.\n",
    "\n",
    "#### Analista de Datos (Data Analyst)\n",
    "\n",
    "Este perfil profesional esta abocado a la recopilaci√≥n y transformaci√≥n de datos para la toma de decisiones empresariales. Para ello se vale del uso de estad√≠stica y de herramientas de gesti√≥n de datos para presentar hechos y respuestas a preguntas del negocio. Las habilidades de comunicaci√≥n son relevantes para este perfil junto al conocimiento del negocio, ya que debe informar y explicar la informaci√≥n obtenida para la toma de decisiones.\n",
    "\n",
    "Responde a preguntas tales como ¬øcu√°ntas ventas se realizaron este mes? ¬øcu√°les han sido los productos m√°s solicitados y donde?, ¬øcu√°l es la proyecci√≥n de ingresos para 2024?, ¬øqu√© volumen de contactos se ha transformado en ventas?, ¬øqu√© modelo de ventas ha sido m√°s exitoso?.\n",
    "\n",
    "Este perfil profesional posee una alta capacidad para la gesti√≥n de captura de datos y la generarci√≥n de procesos de transformaci√≥n de datos, con conocimientos de uso de bases de datos, captura de datos mediante SQL y Excel, y el uso de herramientas de programaci√≥n como Python y R entre otras.\n",
    "\n",
    "La herramienta m√°s poderosa de un analista es un gestor de reportes, del tipo [Power BI](https://powerbi.microsoft.com/es-es/desktop/) o [Tableau](https://www.tableau.com/es-mx) (entre otros), que permite realizar todo tipo de informes o completos paneles de informaci√≥n, orientados a comunicar de forma efectiva los resultados con el fin de la toma de decisiones.\n",
    "\n",
    "Las actividades fundamentales o capacidades de este tipo de perfil son:\n",
    "\n",
    "-   Preprocesamiento de datos\n",
    "-   An√°lisis exploratorio\n",
    "-   Estad√≠stica descriptiva e inferencial\n",
    "-   Visualizaci√≥n de datos\n",
    "-   Comunicaci√≥n de resultados, siendo esta tal vez la funci√≥n m√°s relevante para los fines de la organizaci√≥n\n",
    "\n",
    "#### Cient√≠fico de Datos (Data Scientist)\n",
    "\n",
    "A diferencia de un analista de datos un cient√≠fico de datos est√° orientado a resolver problemas del tipo de descubrimiento de patrones. Para lo cual se vale de herramientas de programaci√≥n, estad√≠stica probabil√≠stica y t√©cnicas de aprendizaje autom√°tico.\n",
    "\n",
    "No es el volumen de datos lo que distingue a un analista de un cient√≠fico (de datos) sino el objetivo a cumplir con esos datos. El analista presenta el estado actual y posiblemente la proyecci√≥n simple (inferencia) de lo que puede ocurrir en un futuro cercano. En tanto, el cient√≠fico de datos debe realizar descubrimiento de patrones, plantear hip√≥tesis y verificarlas (uso del m√©todo cient√≠fico).\n",
    "\n",
    "#### Administrador de Base de datos (DBA)\n",
    "\n",
    "El DBA (Data Base Administrator) es el profesional inform√°tico encargado de la administraci√≥n de una o varias bases de datos gestionando su uso y funcionamiento. Es responsable por el dise√±o de la base de datos y la gesti√≥n de ella, fijando normas que resguardan tanto la seguridad como la integridad de ellas.\n",
    "\n",
    "Este perfil es netamente operativo a cargo de la infraestructura directa asociada a las bases de datos de la organizaci√≥n. Siendo el responsable de la mantenci√≥n de la estructura y las pol√≠ticas de seguridad de las bases. Es este perfil el gestiona adem√°s los roles de acceso y permisos asociados a los usuarios de la organizaci√≥n definidos por el DA y/o el DO.\n",
    "\n",
    "Este perfil es, en √∫ltima instancia el encargado de la creaci√≥n, edici√≥n de las bases de datos y su estructura. Tambi√©n de la construcci√≥n de los procedimientos y funciones requeridos para su funcionamiento.\n",
    "\n",
    "**Funciones**\n",
    "\n",
    "-   Crea la base de datos.\n",
    "-   Implementa los controles necesarios para que se respeten las poliÃÅticas establecidas por el administrador de datos.\n",
    "-   Es el responsable de garantizar que el sistema obtenga las prestaciones deseadas. Presta servicios teÃÅcnicos.\n",
    "-   Mantener la base de datos disponible y actualizada.\n",
    "-   Realizar los respaldos de seguridad. Define pol√≠ticas de seguridad y de respaldo.\n",
    "-   Disponer del accesos a los datos desde las aplicaciones.\n",
    "-   Mantener la seguridad de los datos.\n",
    "-   Dise√±ar y administrar la estructura de los datos.\n",
    "-   Monitorear la actividad de los datos.\n",
    "-   Se asegura de que la comunicaci√≥n del sistema con la base de datos sea expedita.\n",
    "\n",
    "Los Administradores de Bases de Datos son responsables del manejo, mantenimiento, desempe√±o y de la confiabilidad de bases de datos. Asimismo, est√°n a cargo de la mejora y dise√±o de nuevos modelos de las mismas. Manejar una base de datos implica recolectar, clasificar y resguardar la informaci√≥n de manera organizada, por ello, estos profesionales velan por garantizar que la misma est√© debidamente almacenada y segura, adem√°s de que sea de f√°cil acceso cuando sea necesario.\n",
    "\n",
    "#### Desarrollador de Base de Datos\n",
    "\n",
    "Personas como analistas de sistemas y programadores que dise√±an nuevos programas de aplicaci√≥n para los usuarios finales.\n",
    "\n",
    "Los programadores de sistemas inform√°ticos escriben programas para controlar el funcionamiento interno de los ordenadores, lo que implica dise√±ar programas que sean eficientes, r√°pidos y vers√°tiles. Dedican mucho tiempo a probar los programas, y tambi√©n puede instalar, personalizar y dar soporte a estos sistemas operativos.\n",
    "\n",
    "El profesional que debiera asumir este rol es:\n",
    "\n",
    "-   Ingeniero en inform√°tica\n",
    "-   Programador\n",
    "-   Analista programador\n",
    "\n",
    "#### Usuario final\n",
    "\n",
    "Los usuarios finales son las personas que utilizan los datos para su trabajo cotidiano y no son necesariamente del √°rea de la inform√°tica. Normalmente no utilizan la base de datos directamente, sino aplicaciones creadas para ellos a fin de facilitar la manipulaci√≥n de los datos. Estos usuarios s√≥lo acceden a ciertos datos del total.\n",
    "\n",
    "Si bien el usuario final es el receptor de lso datos/informaci√≥n preparada por los perfiles antes mencionados, tambi√©n en su actividad diaria pueden generar necesidades para la toma de nuevos y/o mejorados datos para cumplimentar sus funciones.\n",
    "\n",
    "### La informaci√≥n\n",
    "\n",
    "Informaci√≥n son datos que han sido organizados o preparados en una forma adecuada para apoyar la toma de decisiones: Por ejemplo una lista de productos y su stock sin ning√∫n orden son datos, pero un lista de productos ordenados por stock (de menor a mayor) representa informaci√≥n para el encargado de compras de un supermercado.\n",
    "\n",
    "![Los datos por si solos no conducen a informaci√≥n.](images/conocimiento.jpg)\n",
    "\n",
    "### Discusi√≥n\n",
    "\n",
    "¬øPuede en un momento dado un objeto considerarse como dato y en otro momento como informaci√≥n? ¬øPor qu√©?\n",
    "\n",
    "![Datos e informaci√≥n.](images/datoinfo.png) \n",
    "\n",
    "**Tarea**\n",
    "\n",
    "¬øEs capaz de presentarse a s√≠ mismo sin entregar informaci√≥n si no solo datos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f61ab",
   "metadata": {},
   "source": [
    "## Historia y definici√≥n de Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ec60c",
   "metadata": {},
   "source": [
    "## Conceptos fundamentales y tipos de an√°lisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baec0cb",
   "metadata": {},
   "source": [
    "## Flujo de trabajo de un proyecto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88371b",
   "metadata": {},
   "source": [
    "\n",
    "## Ciclo de Vida de un Proyecto de Data Science\n",
    "\n",
    "El ciclo de vida de un proyecto de Data Science describe las etapas clave desde la concepci√≥n del problema hasta la entrega de soluciones accionables basadas en datos.\n",
    "\n",
    "### üß≠ Etapas Generales\n",
    "\n",
    "1. **Definici√≥n del Problema**\n",
    "2. **Recolecci√≥n de Datos**\n",
    "3. **Preparaci√≥n y Limpieza de Datos**\n",
    "4. **An√°lisis Exploratorio (EDA)**\n",
    "5. **Modelado**\n",
    "6. **Evaluaci√≥n del Modelo**\n",
    "7. **Despliegue**\n",
    "8. **Comunicaci√≥n de Resultados**\n",
    "9. **Mantenimiento**\n",
    "\n",
    "\n",
    "### CRISP-DM\n",
    "**CRISP-DM** (Cross-Industry Standard Process for Data Mining) es una metodolog√≠a desarrollada a finales de los a√±os 90 por un consorcio liderado por IBM, NCR y Daimler-Benz, con el objetivo de estandarizar los procesos de miner√≠a de datos en la industria. Su origen se remonta a la necesidad de crear un marco com√∫n y estructurado que facilitara la aplicaci√≥n de t√©cnicas de an√°lisis de datos en distintos sectores, permitiendo replicabilidad y mejores pr√°cticas.\n",
    "\n",
    "El desarrollo de CRISP-DM fue financiado por la Comisi√≥n Europea y publicado oficialmente en 1999. Desde entonces, se ha convertido en el est√°ndar de facto para proyectos de ciencia de datos y miner√≠a de datos, gracias a su enfoque flexible y adaptable.\n",
    "\n",
    "La metodolog√≠a CRISP-DM se compone de seis fases principales:\n",
    "\n",
    "1. **Comprensi√≥n del negocio (Business Understanding):** Definir los objetivos del proyecto desde la perspectiva del negocio y traducirlos en una problem√°tica de an√°lisis de datos.\n",
    "2. **Comprensi√≥n de los datos (Data Understanding):** Recolectar, describir y explorar los datos iniciales para identificar problemas de calidad y obtener insights preliminares.\n",
    "3. **Preparaci√≥n de los datos (Data Preparation):** Seleccionar, limpiar, transformar y construir los datos necesarios para el modelado.\n",
    "4. **Modelado (Modeling):** Seleccionar y aplicar t√©cnicas de modelado, calibrando los par√°metros para obtener los mejores resultados.\n",
    "5. **Evaluaci√≥n (Evaluation):** Revisar los modelos generados para asegurar que cumplen los objetivos del negocio y decidir los pr√≥ximos pasos.\n",
    "6. **Despliegue (Deployment):** Implementar el modelo en el entorno productivo y asegurar su integraci√≥n con los procesos de negocio.\n",
    "\n",
    "CRISP-DM destaca por su car√°cter iterativo: las fases no son estrictamente secuenciales y es com√∫n regresar a etapas anteriores seg√∫n los hallazgos y necesidades del proyecto. Su √©xito radica en la claridad de sus etapas y en su aplicabilidad a proyectos de cualquier industria, promoviendo la comunicaci√≥n efectiva entre equipos t√©cnicos y de negocio.\n",
    "\n",
    "### OSEMN\n",
    "\n",
    "OSEMN es un acr√≥nimo propuesto por Hilary Mason y Chris Wiggins en 2010 para describir de manera pr√°ctica y sencilla el flujo de trabajo t√≠pico en proyectos de ciencia de datos. El t√©rmino aparece por primera vez en el art√≠culo ‚ÄúA Taxonomy of Data Science‚Äù publicado en *The Data Science Handbook* y popularizado en el blog de O‚ÄôReilly.\n",
    "\n",
    "OSEMN representa cinco etapas fundamentales:\n",
    "\n",
    "1. **Obtain (Obtener):** Recolectar los datos necesarios desde diversas fuentes, como bases de datos, APIs, archivos planos, web scraping, etc.\n",
    "2. **Scrub (Limpiar):** Procesar y limpiar los datos para corregir errores, eliminar duplicados, tratar valores faltantes y asegurar la calidad de la informaci√≥n.\n",
    "3. **Explore (Explorar):** Analizar los datos de manera exploratoria mediante estad√≠sticas descriptivas y visualizaciones para identificar patrones, tendencias y anomal√≠as.\n",
    "4. **Model (Modelar):** Aplicar t√©cnicas de modelado estad√≠stico o de machine learning para extraer conocimiento, hacer predicciones o clasificaciones.\n",
    "5. **iNterpret (Interpretar):** Traducir los resultados del modelo en conclusiones accionables, comunicar hallazgos y generar valor para la toma de decisiones.\n",
    "\n",
    "**Or√≠genes y usos:**  \n",
    "OSEMN surge como una respuesta a la necesidad de un marco √°gil y comprensible para quienes inician en la ciencia de datos, especialmente en entornos educativos, startups y bootcamps. Su enfoque es eminentemente pr√°ctico y t√©cnico, priorizando la manipulaci√≥n y an√°lisis de datos sobre la gesti√≥n de proyectos o la alineaci√≥n con objetivos de negocio. Es ampliamente utilizado para ense√±ar el flujo de trabajo esencial de un cient√≠fico de datos y como gu√≠a r√°pida en proyectos de prototipado o an√°lisis exploratorio.\n",
    "\n",
    "\n",
    "### üîÅ Comparativa entre CRISP-DM y OSEMN\n",
    "\n",
    "| Aspecto                    | CRISP-DM                                              | OSEMN                                                   |\n",
    "|----------------------------|--------------------------------------------------------|----------------------------------------------------------|\n",
    "| Acr√≥nimo                   | Cross-Industry Standard Process for Data Mining        | Obtain, Scrub, Explore, Model, iNterpret                |\n",
    "| Enfoque principal          | Miner√≠a de datos, empresarial                         | Pr√°ctico y t√©cnico                                       |\n",
    "| Etapas                     | 6: Business Understanding, Data Understanding, etc.    | 5: Obtain, Scrub, Explore, Model, Interpret              |\n",
    "| Inclusi√≥n de negocio       | Expl√≠cita                                              | Impl√≠cita                                                |\n",
    "| Nivel de formalizaci√≥n     | Alto                                                   | Medio-bajo                                               |\n",
    "\n",
    "### Team Data Science Process (TDSP)\n",
    "\n",
    "**TDSP** es una metodolog√≠a desarrollada por Microsoft para estructurar, gestionar y escalar proyectos de ciencia de datos en equipos colaborativos. TDSP proporciona un marco de trabajo integral que abarca desde la definici√≥n del problema hasta el despliegue y mantenimiento de soluciones anal√≠ticas, integrando buenas pr√°cticas de ingenier√≠a de software, DevOps y gesti√≥n de proyectos.\n",
    "\n",
    "**Or√≠genes**\n",
    "\n",
    "TDSP surge en 2016 como respuesta a la necesidad de Microsoft de estandarizar y optimizar el ciclo de vida de los proyectos de ciencia de datos en entornos empresariales, especialmente en la nube de Azure. Fue dise√±ado para facilitar la colaboraci√≥n entre cient√≠ficos de datos, ingenieros de datos y desarrolladores, promoviendo la reutilizaci√≥n de c√≥digo, la trazabilidad y la integraci√≥n continua.\n",
    "\n",
    "**Fases principales de TDSP**\n",
    "\n",
    "1. **Business Understanding** (Comprensi√≥n del negocio): Definir objetivos, m√©tricas de √©xito y criterios de aceptaci√≥n alineados con las necesidades del negocio.\n",
    "2. **Data Acquisition and Understanding** (Adquisici√≥n y comprensi√≥n de datos): Recolectar, explorar y validar los datos relevantes para el problema.\n",
    "3. **Modeling** (Modelado): Desarrollar, entrenar y validar modelos predictivos o de an√°lisis.\n",
    "4. **Deployment** (Despliegue): Implementar los modelos en entornos productivos, asegurando su integraci√≥n con aplicaciones y procesos existentes.\n",
    "5. **Customer Acceptance** (Aceptaci√≥n del cliente): Validar los resultados con los usuarios finales y ajustar seg√∫n retroalimentaci√≥n.\n",
    "\n",
    "**Usos y ventajas**\n",
    "\n",
    "- **Colaboraci√≥n:** Facilita el trabajo en equipo mediante repositorios estructurados, control de versiones y documentaci√≥n estandarizada.\n",
    "- **Escalabilidad:** Permite gestionar proyectos complejos y repetibles, integrando herramientas de Azure y DevOps.\n",
    "- **Trazabilidad:** Documenta cada etapa del proyecto, facilitando auditor√≠as y mejoras continuas.\n",
    "- **Despliegue √°gil:** Incluye pr√°cticas para el despliegue automatizado y mantenimiento de modelos en producci√≥n.\n",
    "\n",
    "TDSP es ampliamente utilizado en organizaciones que trabajan con Azure y buscan profesionalizar la gesti√≥n de proyectos de ciencia de datos, especialmente en contextos donde la colaboraci√≥n, la gobernanza y la integraci√≥n con sistemas empresariales son prioritarias.\n",
    "\n",
    "\n",
    "### AWS Data Science Lifecycle\n",
    "\n",
    "El **AWS Data Science Lifecycle** es el marco metodol√≥gico propuesto por Amazon Web Services para gestionar proyectos de ciencia de datos en la nube. Este ciclo de vida est√° dise√±ado para aprovechar la infraestructura escalable, los servicios gestionados y las capacidades de automatizaci√≥n que ofrece AWS, facilitando la implementaci√≥n de soluciones de machine learning y an√°lisis avanzado de datos.\n",
    "\n",
    "**Fases principales del AWS Data Science Lifecycle:**\n",
    "\n",
    "1. **Problem Definition (Definici√≥n del problema):** Identificaci√≥n clara de los objetivos de negocio y los resultados esperados, alineando el proyecto con las necesidades de la organizaci√≥n.\n",
    "2. **Data Collection (Recolecci√≥n de datos):** Obtenci√≥n de datos desde diversas fuentes, como bases de datos, almacenamiento en la nube, APIs o flujos en tiempo real, utilizando servicios como AWS S3, AWS Glue o Amazon RDS.\n",
    "3. **Data Preparation (Preparaci√≥n de datos):** Limpieza, transformaci√≥n y enriquecimiento de los datos mediante herramientas como AWS Glue, Amazon SageMaker Data Wrangler o scripts personalizados.\n",
    "4. **Model Building (Construcci√≥n del modelo):** Desarrollo, entrenamiento y ajuste de modelos de machine learning utilizando Amazon SageMaker, que permite gestionar entornos, recursos y experimentos de manera eficiente.\n",
    "5. **Model Deployment (Despliegue del modelo):** Implementaci√≥n de modelos en producci√≥n a trav√©s de endpoints gestionados, integraci√≥n con aplicaciones o automatizaci√≥n de inferencias usando servicios como SageMaker Endpoint o AWS Lambda.\n",
    "6. **Monitoring & Maintenance (Monitoreo y mantenimiento):** Supervisi√≥n continua del rendimiento del modelo, detecci√≥n de desviaciones (drift), actualizaci√≥n y retraining autom√°tico, aprovechando herramientas como Amazon CloudWatch y SageMaker Model Monitor.\n",
    "\n",
    "**Usos principales:**\n",
    "\n",
    "- **Desarrollo y despliegue de modelos de machine learning** en entornos productivos y escalables.\n",
    "- **Automatizaci√≥n de flujos de trabajo de ciencia de datos** mediante pipelines gestionados.\n",
    "- **Integraci√≥n con servicios cloud** para an√°lisis en tiempo real, procesamiento masivo y almacenamiento seguro.\n",
    "- **Colaboraci√≥n entre equipos** mediante entornos compartidos y control de versiones.\n",
    "\n",
    "**Ventajas:**\n",
    "\n",
    "- **Escalabilidad:** Permite manejar grandes vol√∫menes de datos y cargas de trabajo variables sin preocuparse por la infraestructura.\n",
    "- **Automatizaci√≥n:** Facilita la creaci√≥n de pipelines de datos y modelos, reduciendo errores manuales y acelerando el ciclo de vida.\n",
    "- **Integraci√≥n nativa:** Conecta f√°cilmente con otros servicios de AWS, optimizando el flujo de trabajo de extremo a extremo.\n",
    "- **Despliegue √°gil:** Proporciona herramientas para el despliegue r√°pido y seguro de modelos en producci√≥n.\n",
    "- **Monitoreo avanzado:** Ofrece capacidades integradas para supervisar y mantener modelos en producci√≥n.\n",
    "\n",
    "**Desventajas respecto a otros ciclos:**\n",
    "\n",
    "- **Dependencia de la nube AWS:** El ciclo est√° fuertemente ligado al ecosistema de Amazon, lo que puede limitar la portabilidad a otras plataformas.\n",
    "- **Curva de aprendizaje:** Requiere familiaridad con los servicios y herramientas espec√≠ficas de AWS.\n",
    "- **Costos:** El uso intensivo de servicios gestionados puede incrementar los costos operativos si no se optimizan adecuadamente.\n",
    "- **Menor foco en la gesti√≥n de negocio:** A diferencia de CRISP-DM o TDSP, el ciclo de AWS enfatiza la implementaci√≥n t√©cnica y automatizaci√≥n, dejando en segundo plano la alineaci√≥n estrat√©gica con el negocio.\n",
    "\n",
    "En resumen, el AWS Data Science Lifecycle es ideal para organizaciones que buscan aprovechar la nube para escalar, automatizar y agilizar proyectos de ciencia de datos, especialmente cuando la integraci√≥n y el despliegue continuo son prioritarios. Sin embargo, puede no ser la mejor opci√≥n para equipos que requieren independencia de proveedor o una gesti√≥n de proyectos m√°s orientada al negocio.\n",
    "\n",
    "\n",
    "## üìä Comparativa Extendida: CRISP-DM, OSEMN, TDSP, AWS\n",
    "\n",
    "| Caracter√≠stica                       | CRISP-DM                    | OSEMN                       | TDSP (Microsoft)              | AWS Data Science Lifecycle       |\n",
    "|-------------------------------------|-----------------------------|-----------------------------|-------------------------------|----------------------------------|\n",
    "| Origen                              | IBM                         | Mason & Wiggins (~2010)     | Microsoft Azure               | Amazon Web Services              |\n",
    "| Foco                                | Negocio y miner√≠a de datos | Pr√°ctico-t√©cnico            | Gesti√≥n colaborativa          | Escalabilidad en la nube         |\n",
    "| Etapas                              | 6                           | 5                           | 5                              | 6                                |\n",
    "| Gesti√≥n de proyectos                | Media                       | Baja                        | Alta                           | Alta                             |\n",
    "| Colaboraci√≥n equipo                 | Limitada                    | Individual                  | Fuerte                         | Fuerte                           |\n",
    "| Despliegue/Mantenimiento            | D√©bil                       | No considerado              | Formal con DevOps             | Automatizado con AWS             |\n",
    "| Uso en industria                    | Consultor√≠as, banca         | Startups, bootcamps         | Organizaciones Azure           | Organizaciones con AWS           |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Recomendaci√≥n de Uso\n",
    "\n",
    "| Escenario                                     | Metodolog√≠a sugerida |\n",
    "|----------------------------------------------|----------------------|\n",
    "| Proyectos estructurados                      | CRISP-DM             |\n",
    "| Startups o prototipos r√°pidos                | OSEMN                |\n",
    "| Equipos corporativos con Azure               | TDSP                 |\n",
    "| Proyectos cloud con MLOps                    | AWS Lifecycle        |\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Referencias\n",
    "\n",
    "- CRISP-DM: https://www.the-modeling-agency.com/crisp-dm.pdf\n",
    "- OSEMN: *Doing Data Science* (O'Reilly)\n",
    "- TDSP: https://docs.microsoft.com/en-us/azure/architecture/data-science-process/\n",
    "- AWS: https://docs.aws.amazon.com/sagemaker/latest/dg/data-science-process.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d38e2",
   "metadata": {},
   "source": [
    "## √âtica y privacidad en datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7fe5c",
   "metadata": {},
   "source": [
    "## Herramientas y entornos comunes (Python, Jupyter, Git, VS Code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
