{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1e9943-2418-4e91-acc3-450c4b8fee72",
   "metadata": {},
   "source": [
    "# Árboles\n",
    "Los **árboles de decisión** son modelos predictivos utilizados tanto para tareas de clasificación como de regresión en el aprendizaje supervisado. Su estructura se asemeja a un árbol, donde cada nodo interno representa una pregunta o condición sobre una variable de entrada, cada rama corresponde a una respuesta posible, y cada hoja representa una predicción o resultado final.\n",
    "\n",
    "Un árbol de decisión divide recursivamente el espacio de características en regiones homogéneas respecto a la variable objetivo. El proceso de construcción consiste en seleccionar, en cada nodo, la variable y el umbral que mejor separan los datos según algún criterio de pureza (por ejemplo, *Gini*, *entropía* para clasificación, o *varianza* para regresión).\n",
    "\n",
    "**Formalización matemática:**\n",
    "\n",
    "Para clasificación, el árbol busca particiones que minimicen una función de impureza $I$ en cada nodo $t$:\n",
    "\n",
    "$$\n",
    "I(t) = \\sum_{k=1}^K p_{k}(1 - p_{k})\n",
    "$$\n",
    "\n",
    "donde $p_{k}$ es la proporción de muestras de la clase $k$ en el nodo $t$ (índice de Gini).  \n",
    "Para regresión, se suele minimizar la suma de los errores cuadrados (varianza):\n",
    "\n",
    "$$\n",
    "I(t) = \\frac{1}{N_t} \\sum_{i \\in t} (y_i - \\bar{y}_t)^2\n",
    "$$\n",
    "\n",
    "donde $N_t$ es el número de muestras en el nodo $t$ y $\\bar{y}_t$ es el valor medio de la variable objetivo en ese nodo.\n",
    "\n",
    "El árbol se construye de manera recursiva hasta que se cumple un criterio de parada (profundidad máxima, número mínimo de muestras, etc.).\n",
    "\n",
    "#### Ejemplo de uso en Python (clasificación):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f179b1-63fe-436c-b37f-4c0b921944ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Datos de ejemplo\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Entrenamiento del árbol\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predicción\n",
    "print(clf.predict([[1, 1]]))  # Salida esperada: [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11563572-2ae8-4eae-b934-4decb0ab3478",
   "metadata": {},
   "source": [
    "#### Ejemplo de uso en Python (regresión):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d7c08d-8e71-4295-9cf3-e80d1f3b2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([1.2, 1.9, 3.0, 3.9, 5.1])\n",
    "\n",
    "# Entrenamiento del árbol\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Predicción\n",
    "print(reg.predict([[3.5]]))  # Salida aproximada: [3.0 o 3.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c79fc1-8b7b-4c00-ae7c-a204b369bc81",
   "metadata": {},
   "source": [
    "## Aplicaciones comunes\n",
    "\n",
    "- Diagnóstico médico (clasificación de enfermedades)\n",
    "- Detección de fraude\n",
    "- Predicción de abandono de clientes (*churn*)\n",
    "- Segmentación de clientes en marketing\n",
    "- Predicción de precios de viviendas (regresión)\n",
    "\n",
    "Los árboles de decisión son la base de algoritmos más avanzados como Random Forest y Gradient Boosting. Su principal ventaja es la interpretabilidad y facilidad de visualización, aunque pueden sobreajustar si no se podan o regulan adecuadamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
