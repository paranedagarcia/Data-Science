{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a407a6",
   "metadata": {},
   "source": [
    "# üß† Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc2a63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Scikit-Learn: La \"Caja de Herramientas M√°gica\" del Aprendizaje Autom√°tico**  \n",
    "\n",
    "Imagina que quieres ense√±arle a una computadora a reconocer fotos de perros y gatos, predecir el precio de una casa o agrupar clientes con gustos similares. **Scikit-Learn** es como un **kit de herramientas prefabricadas** que hace todo esto posible, sin que tengas que programar todo desde cero.  \n",
    "\n",
    "Es una **biblioteca de Python** (un conjunto de c√≥digos preescritos) especializada en **aprendizaje autom√°tico (machine learning)**. Su nombre viene de:  \n",
    "- **Sci** (cientifico) + **Kit** (herramientas) + **Learn** (aprender).  \n",
    "- Se pronuncia *\"sai-kit lern\"*.  \n",
    "\n",
    "**Or√≠genes**\n",
    "\n",
    "- Naci√≥ en **2007** como un proyecto de c√≥digo abierto, creado por **David Cournapeau**.  \n",
    "- Luego, otros investigadores (como **INRIA**, un instituto franc√©s) lo mejoraron.  \n",
    "- Hoy es uno de los herramientas m√°s usadas en el mundo para machine learning b√°sico y avanzado.  \n",
    "\n",
    "**¬øPara qu√© se usa?**\n",
    " \n",
    "Scikit-Learn sirve para aplicar **algoritmos de machine learning** de forma sencilla. Algunos ejemplos:  \n",
    "\n",
    "1. **Clasificaci√≥n**  \n",
    "   - ¬øEs este correo **spam o no spam**?  \n",
    "   - ¬øLa imagen muestra un **perro o un gato**?  \n",
    "\n",
    "2. **Regresi√≥n (Predicci√≥n de n√∫meros)**  \n",
    "   - ¬øCu√°nto **costar√° una casa** en 5 a√±os?  \n",
    "   - ¬øCu√°ntas **personas vendr√°n** a un evento?  \n",
    "\n",
    "3. **Agrupamiento (Clustering)**  \n",
    "   - ¬øQu√© **clientes tienen gustos similares**?  \n",
    "   - ¬øC√≥mo se agrupan **noticias por temas** sin etiquetarlas antes?  \n",
    "\n",
    "4. **Preprocesamiento de datos**  \n",
    "   - Limpiar y organizar informaci√≥n desordenada antes de usarla (como convertir texto en n√∫meros).  \n",
    "\n",
    "**¬øC√≥mo funciona?**\n",
    "\n",
    "Scikit-Learn funciona en **3 pasos b√°sicos**:  \n",
    "\n",
    "1. **Elegir un modelo** (como escoger una receta):  \n",
    "   - ¬øVas a predecir algo? Usas **regresi√≥n**.  \n",
    "   - ¬øVas a separar en categor√≠as? Usas **clasificaci√≥n**.  \n",
    "\n",
    "2. **Entrenar el modelo** (como ense√±arle a un ni√±o):  \n",
    "   - Le das **ejemplos** (datos) para que aprenda patrones.  \n",
    "   - Por ejemplo: Muchas fotos etiquetadas como \"perro\" o \"gato\".  \n",
    "\n",
    "3. **Predecir o clasificar** (como ponerlo a prueba):  \n",
    "   - Le das **datos nuevos** (ej: una foto nueva) y te dice si es un perro o un gato.  \n",
    "\n",
    "**Ventajas** ‚úÖ  \n",
    "1. **F√°cil de usar**: Con pocas l√≠neas de c√≥digo, puedes aplicar algoritmos potentes.  \n",
    "2. **Documentaci√≥n excelente**: Tiene gu√≠as y ejemplos para todo.  \n",
    "3. **Compatible**: Funciona bien con otras herramientas de Python (como NumPy y pandas).  \n",
    "4. **Gratis y abierto**: Cualquiera puede usarlo y contribuir a mejorarlo.  \n",
    "5. **Algoritmos preparados**: Incluye SVM, √°rboles de decisi√≥n, redes neuronales simples, etc.  \n",
    "\n",
    "**Desventajas** ‚ùå  \n",
    "1. **No es para deep learning**: Si quieres redes neuronales complejas (como ChatGPT), necesitas herramientas como TensorFlow o PyTorch.  \n",
    "2. **Limitado con datos enormes**: Si tienes **billones de datos**, puede volverse lento (ah√≠ se usan otras herramientas como Spark).  \n",
    "3. **Requiere saber un poco de Python**: Aunque es sencillo, no es totalmente \"arrastrar y soltar\".  \n",
    "\n",
    "**Ejemplo Cotidiano**\n",
    "\n",
    "Imagina que eres un profesor y tienes:  \n",
    "- **Datos**: Las notas de tus alumnos (qui√©n estudi√≥ 1 hora, qui√©n 5 horas, etc.).  \n",
    "- **Objetivo**: Predecir **cu√°nto sacar√° un alumno** si estudia 3 horas.  \n",
    "\n",
    "Con Scikit-Learn:  \n",
    "1. Usas un modelo de **regresi√≥n lineal** (una herramienta para predecir n√∫meros).  \n",
    "2. Le das los datos de ejemplo (horas de estudio vs. notas).  \n",
    "3. El modelo **aprende la relaci√≥n** y te dice: *\"Si estudia 3 horas, sacar√° ~7.5\"*.  \n",
    "\n",
    "\n",
    "**¬øQui√©n lo usa?**\n",
    "\n",
    "- **Cient√≠ficos de datos** (para an√°lisis avanzados).  \n",
    "- **Empresas** (para predecir ventas, clasificar clientes, etc.).  \n",
    "- **Estudiantes** (porque es perfecto para aprender machine learning).  \n",
    "\n",
    "Scikit-Learn es como un **\"libro de recetas\"** que te permite aplicar inteligencia artificial sin ser un experto. Es ideal para empezar en machine learning, pero si necesitas cosas m√°s complejas (como reconocimiento de voz avanzado), deber√°s usar otras herramientas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ba2db",
   "metadata": {},
   "source": [
    "#### Regresi√≥n lineal\n",
    "La **regresi√≥n lineal** es una t√©cnica estad√≠stica y de machine learning utilizada para modelar la relaci√≥n entre una variable dependiente (o respuesta) y una o m√°s variables independientes (o predictoras) asumiendo que esta relaci√≥n es lineal. El objetivo principal es encontrar la l√≠nea recta (en el caso de una sola variable independiente) o el hiperplano (en el caso de m√∫ltiples variables) que mejor se ajusta a los datos observados, minimizando la suma de los errores cuadrados entre los valores predichos y los valores reales.\n",
    "\n",
    "En la regresi√≥n lineal simple, la relaci√≥n se expresa mediante la ecuaci√≥n:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\epsilon\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $y$ es la variable dependiente,\n",
    "- $x$ es la variable independiente,\n",
    "- $\\beta_0$ es el intercepto,\n",
    "- $\\beta_1$ es el coeficiente de regresi√≥n (pendiente),\n",
    "- $\\epsilon$ es el t√©rmino de error.\n",
    "\n",
    "En la regresi√≥n lineal m√∫ltiple, se extiende a varias variables independientes:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n + \\epsilon\n",
    "$$\n",
    "\n",
    "La regresi√≥n lineal es ampliamente utilizada por su simplicidad, interpretabilidad y eficiencia, aunque asume que la relaci√≥n entre variables es lineal, que los errores son independientes y distribuidos normalmente, y que no existe multicolinealidad entre las variables independientes.\n",
    "\n",
    "**Ejemplo 1: Regresi√≥n lineal simple con scikit-learn**\n",
    "\n",
    "Debes instalar la librer√≠a scikit-learn para usar LinearRegression:\n",
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf09e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ejemplo 1: Regresi√≥n lineal simple con scikit-learn\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Datos de ejemplo\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Regresi√≥n lineal simple con scikit-learn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X, y)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo.predict(X)\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.scatter(X, y, color='blue', label='Datos reales')\n",
    "plt.plot(X, y_pred, color='red', label='Recta de regresi√≥n')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Regresi√≥n lineal simple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57f2e8",
   "metadata": {},
   "source": [
    "**Ejemplo 2: Regresi√≥n lineal m√∫ltiple**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c82e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: [1. 1.]\n",
      "Intercepto: 1.7763568394002505e-15\n"
     ]
    }
   ],
   "source": [
    "# Datos de ejemplo para regresi√≥n m√∫ltiple\n",
    "X_multi = np.array([[1, 2], [2, 1], [3, 4], [4, 3], [5, 5]])\n",
    "y_multi = np.array([3, 3, 7, 7, 10])\n",
    "\n",
    "modelo_multi = LinearRegression()\n",
    "modelo_multi.fit(X_multi, y_multi)\n",
    "\n",
    "print(\"Coeficientes:\", modelo_multi.coef_)\n",
    "print(\"Intercepto:\", modelo_multi.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b352b",
   "metadata": {},
   "source": [
    "#### √Årboles\n",
    "Los **√°rboles de decisi√≥n** son modelos predictivos utilizados tanto para tareas de clasificaci√≥n como de regresi√≥n en el aprendizaje supervisado. Su estructura se asemeja a un √°rbol, donde cada nodo interno representa una pregunta o condici√≥n sobre una variable de entrada, cada rama corresponde a una respuesta posible, y cada hoja representa una predicci√≥n o resultado final.\n",
    "\n",
    "Un √°rbol de decisi√≥n divide recursivamente el espacio de caracter√≠sticas en regiones homog√©neas respecto a la variable objetivo. El proceso de construcci√≥n consiste en seleccionar, en cada nodo, la variable y el umbral que mejor separan los datos seg√∫n alg√∫n criterio de pureza (por ejemplo, *Gini*, *entrop√≠a* para clasificaci√≥n, o *varianza* para regresi√≥n).\n",
    "\n",
    "**Formalizaci√≥n matem√°tica:**\n",
    "\n",
    "Para clasificaci√≥n, el √°rbol busca particiones que minimicen una funci√≥n de impureza $I$ en cada nodo $t$:\n",
    "\n",
    "$$\n",
    "I(t) = \\sum_{k=1}^K p_{k}(1 - p_{k})\n",
    "$$\n",
    "\n",
    "donde $p_{k}$ es la proporci√≥n de muestras de la clase $k$ en el nodo $t$ (√≠ndice de Gini).  \n",
    "Para regresi√≥n, se suele minimizar la suma de los errores cuadrados (varianza):\n",
    "\n",
    "$$\n",
    "I(t) = \\frac{1}{N_t} \\sum_{i \\in t} (y_i - \\bar{y}_t)^2\n",
    "$$\n",
    "\n",
    "donde $N_t$ es el n√∫mero de muestras en el nodo $t$ y $\\bar{y}_t$ es el valor medio de la variable objetivo en ese nodo.\n",
    "\n",
    "El √°rbol se construye de manera recursiva hasta que se cumple un criterio de parada (profundidad m√°xima, n√∫mero m√≠nimo de muestras, etc.).\n",
    "\n",
    "#### Ejemplo de uso en Python (clasificaci√≥n):\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Entrenamiento del √°rbol\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predicci√≥n\n",
    "print(clf.predict([[1, 1]]))  # Salida esperada: [1]\n",
    "```\n",
    "\n",
    "#### Ejemplo de uso en Python (regresi√≥n):\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Datos de ejemplo\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([1.2, 1.9, 3.0, 3.9, 5.1])\n",
    "\n",
    "# Entrenamiento del √°rbol\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Predicci√≥n\n",
    "print(reg.predict([[3.5]]))  # Salida aproximada: [3.0 o 3.9]\n",
    "```\n",
    "\n",
    "#### Aplicaciones comunes\n",
    "\n",
    "- Diagn√≥stico m√©dico (clasificaci√≥n de enfermedades)\n",
    "- Detecci√≥n de fraude\n",
    "- Predicci√≥n de abandono de clientes (*churn*)\n",
    "- Segmentaci√≥n de clientes en marketing\n",
    "- Predicci√≥n de precios de viviendas (regresi√≥n)\n",
    "\n",
    "Los √°rboles de decisi√≥n son la base de algoritmos m√°s avanzados como Random Forest y Gradient Boosting. Su principal ventaja es la interpretabilidad y facilidad de visualizaci√≥n, aunque pueden sobreajustar si no se podan o regulan adecuadamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
